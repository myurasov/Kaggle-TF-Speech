{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.io import wavfile\n",
    "from glob import glob\n",
    "import re\n",
    "import warnings\n",
    "from numpy.random import random, uniform, randint, choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     1,
     96,
     125,
     149
    ]
   },
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    def __init__(self, input_dir):\n",
    "\n",
    "        self.debug = False\n",
    "        self._input_files = None\n",
    "        self._cached_waves = {}\n",
    "\n",
    "        # msg normalization params\n",
    "        # inspired by https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py#L529\n",
    "        self.samplewise_norm = True\n",
    "        # following two needs to be computed in many msgs\n",
    "        self.msg_mean = None\n",
    "        self.msg_std = None\n",
    "\n",
    "        self.input_dir = input_dir\n",
    "        self.sample_rate = 16000\n",
    "        self.duration = 1.  # sec\n",
    "        self.n_fft = 512\n",
    "        self.n_mels = 64\n",
    "        self.msg_w = 256\n",
    "\n",
    "        # valid labels\n",
    "        self.valid_labels = set(LABELS)\n",
    "\n",
    "        self.silence_files = glob(self.input_dir + '/_background_noise_/*.wav')\n",
    "\n",
    "        # random mixing settings\n",
    "\n",
    "        self.mix_with = {}\n",
    "\n",
    "        self.mix_with[self.input_dir +\n",
    "                      '/_background_noise_/doing_the_dishes.wav'] = {\n",
    "                          'volume': [0.05, 0.75],\n",
    "                          'probability': 0.2\n",
    "                      }\n",
    "\n",
    "        self.mix_with[self.input_dir +\n",
    "                      '/_background_noise_/exercise_bike.wav'] = {\n",
    "                          'volume': [0.05, 0.75],\n",
    "                          'probability': 0.2\n",
    "                      }\n",
    "\n",
    "        self.mix_with[self.input_dir +\n",
    "                      '/_background_noise_/white_noise.wav'] = {\n",
    "                          'volume': [0.001, 0.06],\n",
    "                          'probability': 0.2\n",
    "                      }\n",
    "\n",
    "        self.mix_with[self.input_dir +\n",
    "                      '/_background_noise_/dude_miaowing.wav'] = {\n",
    "                          'volume': [0.05, 0.75],\n",
    "                          'probability': 0.2\n",
    "                      }\n",
    "\n",
    "        self.mix_with[self.input_dir +\n",
    "                      '/_background_noise_/pink_noise.wav'] = {\n",
    "                          'volume': [0.001, 0.06],\n",
    "                          'probability': 0.2\n",
    "                      }\n",
    "\n",
    "        self.mix_with[self.input_dir +\n",
    "                      '/_background_noise_/running_tap.wav'] = {\n",
    "                          'volume': [0.25, 0.75],\n",
    "                          'probability': 0.2\n",
    "                      }\n",
    "\n",
    "        # random transforms\n",
    "\n",
    "        self.transforms = {\n",
    "            'pitch': {\n",
    "                'probability': 0.5,\n",
    "                'range': [-10., 10.]\n",
    "            },\n",
    "            'speed': {\n",
    "                'probability': 0.33,\n",
    "                'range': [0.5, 2.]\n",
    "            },\n",
    "            'volume': {\n",
    "                'probability': 0.25,\n",
    "                'range': [0.5, 1.25]\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # silence-specific transforms\n",
    "        self.silence_transforms = {\n",
    "            'volume': {\n",
    "                'probability': 1.,\n",
    "                'range': [0.01, 1.]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # compute mel-scaled spectrogram\n",
    "    def msg(self, wave):\n",
    "\n",
    "        hop_length = int(1 + self.duration * self.sample_rate //\n",
    "                         (self.msg_w - 1))\n",
    "        desired_wave_len = int(hop_length * (self.msg_w - 1))\n",
    "\n",
    "        # pad wave if neccessary to get the desired msg width\n",
    "        if desired_wave_len > len(wave):\n",
    "            wave = np.pad(\n",
    "                wave, (0, desired_wave_len - len(wave)),\n",
    "                'constant',\n",
    "                constant_values=(0.))\n",
    "\n",
    "        # trim wave if it's too long\n",
    "        elif len(wave) > desired_wave_len:\n",
    "            wave = wave[:desired_wave_len]\n",
    "\n",
    "        msg = librosa.feature.melspectrogram(\n",
    "            y=wave,\n",
    "            sr=self.sample_rate,\n",
    "            hop_length=hop_length,\n",
    "            n_fft=self.n_fft,\n",
    "            n_mels=self.n_mels)\n",
    "        msg = librosa.logamplitude(msg**2, ref_power=1.)\n",
    "        assert msg.shape[1] == self.msg_w\n",
    "\n",
    "        return msg.astype(np.float32)\n",
    "\n",
    "    @property\n",
    "    def input_files(self):\n",
    "        if self._input_files is None:\n",
    "\n",
    "            def _get_label(path):\n",
    "                m = re.findall('audio/([^/]+)/', path)\n",
    "                if not m: return None\n",
    "                if m[0] in self.valid_labels: return m[0]\n",
    "                else: return 'unknown'\n",
    "\n",
    "            ff = glob(self.input_dir + '/**/*.wav', recursive=True)\n",
    "            ff = filter(lambda x: '_background_noise_/' not in x, ff)\n",
    "\n",
    "            self._input_files = {}\n",
    "\n",
    "            for f in ff:\n",
    "                label = _get_label(f)\n",
    "                if label not in self._input_files:\n",
    "                    self._input_files[label] = [f]\n",
    "                else:\n",
    "                    self._input_files[label].append(f)\n",
    "\n",
    "        return self._input_files\n",
    "\n",
    "    # read file and extract random segment\n",
    "    def _load_random_segment(self, file):\n",
    "\n",
    "        if file not in self._cached_waves:\n",
    "            # supress warnings\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter('ignore')\n",
    "                sr, wave = wavfile.read(file)\n",
    "                wave = wave.astype(np.float32)\n",
    "            self._cached_waves[file] = (sr, wave)\n",
    "\n",
    "        sr, wave = self._cached_waves[file]\n",
    "        assert sr == self.sample_rate\n",
    "        l = int(sr * self.duration)\n",
    "\n",
    "        start = randint(0, len(wave) - l)\n",
    "        wave = wave[start:start + l]\n",
    "\n",
    "        return wave\n",
    "\n",
    "    # gen random audio sample for 'silence' label\n",
    "    def generate_silence_audio(self):\n",
    "        silence_file = choice(self.silence_files)\n",
    "        if self.debug: print('silence file', silence_file)\n",
    "        wave = self._load_random_segment(silence_file)\n",
    "        wave = self.apply_transforms(wave, silence_transforms=True)\n",
    "        return wave\n",
    "\n",
    "    # gen random audio for non-silence labels\n",
    "    def generate_audio(self):\n",
    "        # pick label\n",
    "        label = choice(list(self.valid_labels))\n",
    "\n",
    "        if 'silence' == label:\n",
    "            return self.generate_silence_audio(), label\n",
    "        else:\n",
    "            # pick wav file\n",
    "            file = choice(self.input_files[label])\n",
    "\n",
    "            if self.debug: print('file', file)\n",
    "\n",
    "            sr, wave = wavfile.read(file)\n",
    "            wave = wave.astype(np.float32)\n",
    "            assert sr == self.sample_rate\n",
    "\n",
    "            # pad too short ones/trim too long\n",
    "\n",
    "            desired_len = int(self.duration * self.sample_rate)\n",
    "            len_diff = len(wave) - desired_len\n",
    "\n",
    "            if len_diff < 0:  # too short\n",
    "                wave = np.pad(wave, (-len_diff + 1) // 2,\n",
    "                              'median')[:desired_len]\n",
    "            elif len_diff > 0:  # too long\n",
    "                wave = wave[len_diff // 2:desired_len + len_diff // 2]\n",
    "\n",
    "            assert len(wave) == desired_len\n",
    "\n",
    "            # transforms\n",
    "            wave = self.apply_transforms(wave)\\\n",
    "\n",
    "            return wave, label\n",
    "\n",
    "    # apply randon transforms\n",
    "    def apply_transforms(self, wave, silence_transforms=False):\n",
    "\n",
    "        if silence_transforms:\n",
    "            # silence/volume\n",
    "            t = self.silence_transforms['volume']\n",
    "            if random() < t['probability']:\n",
    "                factor = uniform(*t['range'])\n",
    "                wave = self.transform_volume(wave, factor)\n",
    "\n",
    "        # mix\n",
    "        for file, options in self.mix_with.items():\n",
    "            if random() < options['probability']:\n",
    "                wave2 = self._load_random_segment(file)\n",
    "                volume2 = uniform(*options['volume'])\n",
    "\n",
    "                if self.debug:\n",
    "                    print('mixing with %s at %.2f vol' % (file, volume2))\n",
    "\n",
    "                wave = self.mix(wave, 1., wave2, volume2)\n",
    "\n",
    "        # pitch\n",
    "        t = self.transforms['pitch']\n",
    "        if random() < t['probability']:\n",
    "            wave = self.transform_pitch(wave, uniform(*t['range']))\n",
    "\n",
    "        # speed\n",
    "        t = self.transforms['speed']\n",
    "        if random() < t['probability']:\n",
    "            wave = self.transform_speed(wave, uniform(*t['range']))\n",
    "\n",
    "        return wave\n",
    "\n",
    "    def transform_pitch(self, wave, factor):\n",
    "        if self.debug: print('transforming pitch', factor)\n",
    "        return librosa.effects.pitch_shift(wave, self.sample_rate, factor)\n",
    "\n",
    "    def transform_volume(self, wave, factor):\n",
    "        if self.debug: print('transforming volume', factor)\n",
    "        return np.multiply(wave, factor)\n",
    "\n",
    "    def transform_speed(self, wave, factor):\n",
    "        if self.debug: print('transforming speed', factor)\n",
    "\n",
    "        orig_len = len(wave)\n",
    "        wave = librosa.effects.time_stretch(wave, factor)\n",
    "        len_diff = len(wave) - orig_len\n",
    "\n",
    "        # pad/trim from the center\n",
    "        if len_diff < 0:\n",
    "            wave = np.pad(wave, (-len_diff + 1) // 2, 'median')[:orig_len]\n",
    "        elif len_diff > 0:\n",
    "            wave = wave[len_diff // 2:orig_len + len_diff // 2]\n",
    "\n",
    "        assert len(wave) == orig_len\n",
    "        return wave\n",
    "\n",
    "    def mix(self, wave1, volume1, wave2, volume2):\n",
    "        if volume1 + volume2 > 0:\n",
    "            volume1, volume2 = \\\n",
    "                volume1 / (volume1 + volume2), \\\n",
    "                volume2 / (volume1 + volume2)\n",
    "            return wave1 * volume1 + wave2 * volume2\n",
    "\n",
    "    def normalize_msg(self, msg):\n",
    "\n",
    "        if self.msg_mean is not None:\n",
    "            msg -= self.msg_mean\n",
    "\n",
    "        if self.msg_std is not None:\n",
    "            msg /= self.msg_std + 1e-7\n",
    "\n",
    "        if self.samplewise_norm:\n",
    "            msg -= np.mean(msg)\n",
    "            msg /= np.std(msg) + 1e-7\n",
    "\n",
    "        return msg\n",
    "\n",
    "    def compute_msg_norm_params(self, n_steps=100):\n",
    "        msgs = np.zeros((n_steps, self.n_mels, self.msg_w), dtype=np.float32)\n",
    "\n",
    "        for i in range(n_steps):\n",
    "            msgs[i] = self.msg(self.generate_audio()[0])\n",
    "\n",
    "        self.msg_mean = np.mean(msgs)\n",
    "        self.msg_std = np.std(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
