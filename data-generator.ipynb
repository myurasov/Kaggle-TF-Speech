{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.io import wavfile\n",
    "from glob import glob\n",
    "import re\n",
    "import warnings\n",
    "from numpy.random import random, uniform, randint, choice\n",
    "import os\n",
    "import shutil\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\n",
    "    'yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go',\n",
    "    'unknown', 'silence'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     1,
     96,
     125,
     149
    ]
   },
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    def __init__(self,\n",
    "                 input_dir,\n",
    "                 labels=LABELS,\n",
    "                 bg_noise_dir=None,\n",
    "                 silence_dir=None,\n",
    "                 extra_silence_dir=None):\n",
    "\n",
    "        self.debug = False\n",
    "        self._input_files = None\n",
    "        self._cached_waves = {}\n",
    "        self._label_onehots = None\n",
    "        self.val_files = {}\n",
    "\n",
    "        # msg normalization params\n",
    "        # inspired by https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py#L529\n",
    "        self.samplewise_norm = True\n",
    "        # following two needs to be computed on many msgs\n",
    "        self.msg_mean = 116.536\n",
    "        self.msg_std = 21.5913\n",
    "\n",
    "        self.input_dir = input_dir\n",
    "        self.sample_rate = 16000\n",
    "        self.duration = 1.  # sec\n",
    "        self.n_fft = 512\n",
    "        self.n_mels = 64\n",
    "        self.msg_w = 64\n",
    "\n",
    "        # valid labels\n",
    "        self.labels = labels\n",
    "\n",
    "        # dirs for bg noise/silence\n",
    "        self.bg_noise_dir = self.input_dir + '/_background_noise_' if bg_noise_dir is None else bg_noise_dir\n",
    "        self.silence_dir = self.input_dir + '/_background_noise_' if silence_dir is None else silence_dir\n",
    "\n",
    "        # silence files\n",
    "        self.silence_files = glob(self.silence_dir + '/*.wav')\n",
    "\n",
    "        # extra silence files\n",
    "        if extra_silence_dir:\n",
    "            self.extra_silence_files = glob(extra_silence_dir + '/*.wav')\n",
    "            self.silence_files += self.extra_silence_files\n",
    "        else:\n",
    "            self.extra_silence_files = None\n",
    "\n",
    "        # random transforms\n",
    "\n",
    "        self.transforms = {\n",
    "            'pitch': {\n",
    "                'probability': 0.5,\n",
    "                'range': [-10., 10.]\n",
    "            },\n",
    "            'speed': {\n",
    "                'probability': 0.33,\n",
    "                'range': [0.5, 2.]\n",
    "            },\n",
    "            'volume': {\n",
    "                'probability': 0.25,\n",
    "                'range': [0.5, 1.25]\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # silence-specific transforms\n",
    "        self.silence_transforms = {\n",
    "            'volume': {\n",
    "                'probability': 1.,\n",
    "                'range': [0.01, 1.]\n",
    "            }\n",
    "        }\n",
    "\n",
    "        self._init_mixing_params()\n",
    "\n",
    "    def _init_mixing_params(self):\n",
    "        # random mixing settings\n",
    "\n",
    "        self.mix_with = {}\n",
    "\n",
    "        self.mix_with[self.bg_noise_dir + '/doing_the_dishes.wav'] = {\n",
    "            'volume': [0.05, 0.75],\n",
    "            'probability': 0.2\n",
    "        }\n",
    "\n",
    "        self.mix_with[self.bg_noise_dir + '/exercise_bike.wav'] = {\n",
    "            'volume': [0.05, 0.75],\n",
    "            'probability': 0.2\n",
    "        }\n",
    "\n",
    "        self.mix_with[self.bg_noise_dir + '/white_noise.wav'] = {\n",
    "            'volume': [0.001, 0.06],\n",
    "            'probability': 0.2\n",
    "        }\n",
    "\n",
    "        self.mix_with[self.bg_noise_dir + '/dude_miaowing.wav'] = {\n",
    "            'volume': [0.05, 0.75],\n",
    "            'probability': 0.2\n",
    "        }\n",
    "\n",
    "        self.mix_with[self.bg_noise_dir + '/pink_noise.wav'] = {\n",
    "            'volume': [0.001, 0.06],\n",
    "            'probability': 0.2\n",
    "        }\n",
    "\n",
    "        self.mix_with[self.bg_noise_dir + '/running_tap.wav'] = {\n",
    "            'volume': [0.25, 0.75],\n",
    "            'probability': 0.2\n",
    "        }\n",
    "\n",
    "        # extra silence files\n",
    "        if self.extra_silence_files:\n",
    "            for f in self.extra_silence_files:\n",
    "                self.mix_with[f] = {\n",
    "                    'volume': [0.25, 0.75],\n",
    "                    'probability': 1. / len(self.extra_silence_files)\n",
    "                }\n",
    "\n",
    "    # compute mel-scaled spectrogram\n",
    "    def msg(self, wave):\n",
    "\n",
    "        hop_length = int(1 + self.duration * self.sample_rate //\n",
    "                         (self.msg_w - 1))\n",
    "        desired_wave_len = int(hop_length * (self.msg_w - 1))\n",
    "\n",
    "        # pad wave if neccessary to get the desired msg width\n",
    "        if desired_wave_len > len(wave):\n",
    "            wave = np.pad(wave, (0, desired_wave_len - len(wave)), 'median')\n",
    "\n",
    "        # trim wave if it's too long\n",
    "        elif len(wave) > desired_wave_len:\n",
    "            wave = wave[:desired_wave_len]\n",
    "\n",
    "        msg = librosa.feature.melspectrogram(\n",
    "            y=wave,\n",
    "            sr=self.sample_rate,\n",
    "            hop_length=hop_length,\n",
    "            n_fft=self.n_fft,\n",
    "            n_mels=self.n_mels)\n",
    "        msg = librosa.logamplitude(msg**2, ref_power=1.)\n",
    "        assert msg.shape[1] == self.msg_w\n",
    "\n",
    "        msg = msg.astype(np.float32)\n",
    "\n",
    "        return msg\n",
    "\n",
    "    @property\n",
    "    def input_files(self):\n",
    "        if self._input_files is None:\n",
    "\n",
    "            _labels_set = set(self.labels)\n",
    "\n",
    "            def _get_label(path):\n",
    "                m = re.findall('([^/]+)/', path)\n",
    "                if not m: return None\n",
    "                if m[0] in _labels_set:\n",
    "                    return m[0]\n",
    "                else:\n",
    "                    return 'unknown'\n",
    "\n",
    "            ff = glob(self.input_dir + '/**/*.wav', recursive=True)\n",
    "            ff = filter(lambda x: '_background_noise_/' not in x, ff)\n",
    "            ff = [os.path.relpath(x, self.input_dir) for x in ff]\n",
    "\n",
    "            self._input_files = {}\n",
    "\n",
    "            for f in ff:\n",
    "                label = _get_label(f)\n",
    "                if label not in self._input_files:\n",
    "                    self._input_files[label] = [f]\n",
    "                else:\n",
    "                    self._input_files[label].append(f)\n",
    "\n",
    "        return self._input_files\n",
    "\n",
    "    def _normalize_wave_len(self, wave, min_samples=None, max_samples=None):\n",
    "        if min_samples is not None and len(wave) < min_samples:\n",
    "            len_to_add = min_samples - len(wave)\n",
    "            wave = np.pad(wave, (len_to_add + 1) // 2, 'median')[:min_samples]\n",
    "\n",
    "        if max_samples is not None and len(wave) > max_samples:\n",
    "            len_to_cut = len(wave) - max_samples\n",
    "            wave = wave[len_to_cut // 2:max_samples + len_to_cut // 2]\n",
    "\n",
    "        return wave\n",
    "\n",
    "    # read file and extract random segment\n",
    "    def _load_random_segment(self, file):\n",
    "\n",
    "        if file not in self._cached_waves:\n",
    "            # supress warnings\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter('ignore')\n",
    "                sr, wave = wavfile.read(file)\n",
    "                wave = wave.astype(np.float32)\n",
    "\n",
    "            # pad if too short\n",
    "            wave = self._normalize_wave_len(wave, \\\n",
    "                min_samples=int(self.duration * self.sample_rate))\n",
    "\n",
    "            # save to cache\n",
    "            self._cached_waves[file] = (sr, wave)\n",
    "\n",
    "        sr, wave = self._cached_waves[file]\n",
    "        assert sr == self.sample_rate\n",
    "        desired_len = int(sr * self.duration)\n",
    "\n",
    "        start = randint(0, max(1, len(wave) - desired_len))\n",
    "        wave = wave[start:start + desired_len]\n",
    "\n",
    "        return wave\n",
    "\n",
    "    # gen random audio sample for 'silence' label\n",
    "    def generate_silence_audio(self):\n",
    "        silence_file = choice(self.silence_files)\n",
    "        if self.debug: print('silence file', silence_file)\n",
    "        wave = self._load_random_segment(silence_file)\n",
    "        wave = self.apply_transforms(wave, silence_transforms=True)\n",
    "        return wave\n",
    "\n",
    "    # gen random audio for non-silence labels\n",
    "    def generate_audio(self, label=None, file=None, transform=True):\n",
    "        # pick label\n",
    "        if label is None: label = choice(list(self.labels))\n",
    "\n",
    "        if 'silence' == label:\n",
    "            return self.generate_silence_audio(), label\n",
    "        else:\n",
    "            # pick wav file\n",
    "            if file is None:\n",
    "                while file is None or file in self.val_files:\n",
    "                    file = choice(self.input_files[label])\n",
    "\n",
    "            if self.debug: print('file', file)\n",
    "\n",
    "            sr, wave = wavfile.read(os.path.join(self.input_dir, file))\n",
    "            wave = wave.astype(np.float32)\n",
    "            assert sr == self.sample_rate\n",
    "\n",
    "            # pad too short ones/trim too long\n",
    "            desired_len = int(self.duration * self.sample_rate)\n",
    "            wave = self._normalize_wave_len(\n",
    "                wave, min_samples=desired_len, max_samples=desired_len)\n",
    "            assert len(wave) == desired_len\n",
    "\n",
    "            # transforms\n",
    "            if transform: wave = self.apply_transforms(wave)\n",
    "\n",
    "            return wave, label\n",
    "\n",
    "    # apply randon transforms\n",
    "    def apply_transforms(self, wave, silence_transforms=False):\n",
    "\n",
    "        if silence_transforms:\n",
    "            # silence/volume\n",
    "            t = self.silence_transforms['volume']\n",
    "            if random() < t['probability']:\n",
    "                factor = uniform(*t['range'])\n",
    "                wave = self.transform_volume(wave, factor)\n",
    "\n",
    "        # mix\n",
    "        for file, options in self.mix_with.items():\n",
    "            if random() < options['probability']:\n",
    "                wave2 = self._load_random_segment(file)\n",
    "                volume2 = uniform(*options['volume'])\n",
    "\n",
    "                if self.debug:\n",
    "                    print('mixing with %s at %.2f vol' % (file, volume2))\n",
    "\n",
    "                wave = self.mix(wave, 1., wave2, volume2)\n",
    "\n",
    "        # pitch\n",
    "        t = self.transforms['pitch']\n",
    "        if random() < t['probability']:\n",
    "            wave = self.transform_pitch(wave, uniform(*t['range']))\n",
    "\n",
    "        # speed\n",
    "        t = self.transforms['speed']\n",
    "        if random() < t['probability']:\n",
    "            wave = self.transform_speed(wave, uniform(*t['range']))\n",
    "\n",
    "        return wave\n",
    "\n",
    "    def transform_pitch(self, wave, factor):\n",
    "        if self.debug: print('transforming pitch', factor)\n",
    "        return librosa.effects.pitch_shift(wave, self.sample_rate, factor)\n",
    "\n",
    "    def transform_volume(self, wave, factor):\n",
    "        if self.debug: print('transforming volume', factor)\n",
    "        return np.multiply(wave, factor)\n",
    "\n",
    "    def transform_speed(self, wave, factor):\n",
    "        if self.debug: print('transforming speed', factor)\n",
    "\n",
    "        orig_len = len(wave)\n",
    "        wave = librosa.effects.time_stretch(wave, factor)\n",
    "\n",
    "        # pad/trim from the center\n",
    "        wave = self._normalize_wave_len(\n",
    "            wave, min_samples=orig_len, max_samples=orig_len)\n",
    "\n",
    "        assert len(wave) == orig_len\n",
    "        return wave\n",
    "\n",
    "    def mix(self, wave1, volume1, wave2, volume2):\n",
    "        if volume1 + volume2 > 0:\n",
    "            volume1, volume2 = \\\n",
    "                volume1 / (volume1 + volume2), \\\n",
    "                volume2 / (volume1 + volume2)\n",
    "            return wave1 * volume1 + wave2 * volume2\n",
    "\n",
    "    def normalize_msg(self, msg):\n",
    "\n",
    "        if self.msg_mean is not None:\n",
    "            msg -= self.msg_mean\n",
    "\n",
    "        if self.msg_std is not None:\n",
    "            msg /= self.msg_std + 1e-7\n",
    "\n",
    "        if self.samplewise_norm:\n",
    "            msg -= np.mean(msg)\n",
    "            msg /= np.std(msg) + 1e-7\n",
    "\n",
    "        return msg\n",
    "\n",
    "    def compute_msg_norm_params(self, n_steps=100):\n",
    "        msgs = np.zeros((n_steps, self.n_mels, self.msg_w), dtype=np.float32)\n",
    "\n",
    "        for i in range(n_steps):\n",
    "            msgs[i] = self.msg(self.generate_audio()[0])\n",
    "\n",
    "        self.msg_mean = np.mean(msgs)\n",
    "        self.msg_std = np.std(msgs)\n",
    "\n",
    "    def _init_onehots(self):\n",
    "        def _onehot(l, o):\n",
    "            z = np.zeros(l, dtype=np.float32)\n",
    "            z[o] = 1.\n",
    "            return z\n",
    "\n",
    "        self._label_onehots = {\n",
    "            label: _onehot(len(self.labels), i)\n",
    "            for i, label in enumerate(self.labels)\n",
    "        }\n",
    "\n",
    "    def label_to_onehot(self, label):\n",
    "        if self._label_onehots is None:\n",
    "            self._init_onehots()\n",
    "        return self._label_onehots[label]\n",
    "\n",
    "    def onehot_to_label(self, onehot):\n",
    "        return self.labels[np.argmax(onehot)]\n",
    "\n",
    "    def generate_val_set(self, n=1000):\n",
    "\n",
    "        val_X = np.zeros((n, self.n_mels, self.msg_w), dtype=np.float32)\n",
    "        val_Y = np.zeros((n, len(self.labels)))\n",
    "\n",
    "        # pick files for non-silence labels\n",
    "        if not self.val_files:\n",
    "            self.val_files = {}\n",
    "\n",
    "            for i in range(n):\n",
    "                label = choice(self.labels)\n",
    "\n",
    "                if 'silence' != label:\n",
    "                    file = ''\n",
    "                    while file == '' or file in self.val_files:\n",
    "                        file = choice(self.input_files[label])\n",
    "                    self.val_files[file] = label\n",
    "\n",
    "        # gen non-silence samples\n",
    "        i = 0\n",
    "        for file, label in self.val_files.items():\n",
    "            wave, _ = self.generate_audio(\n",
    "                label=label, file=file, transform=False)\n",
    "            msg = self.msg(wave)\n",
    "            msg = self.normalize_msg(msg)\n",
    "            val_X[i] = msg\n",
    "            val_Y[i] = self.label_to_onehot(label)\n",
    "            i += 1\n",
    "\n",
    "        # silence samples\n",
    "        for j in range(i, n):\n",
    "            wave, label = self.generate_audio('silence', transform=True)\n",
    "            msg = self.msg(wave)\n",
    "            msg = self.normalize_msg(msg)\n",
    "            val_X[j] = msg\n",
    "            val_Y[j] = self.label_to_onehot(label)\n",
    "\n",
    "        return np.expand_dims(val_X, 3), val_Y\n",
    "\n",
    "    def _gen_training_samples(self, n, start_i, tmp_dir):\n",
    "        X = np.zeros((n, self.n_mels, self.msg_w, 1), dtype=np.float32)\n",
    "        Y = np.zeros((n, len(self.labels)), dtype=np.float32)\n",
    "        for i in range(n):\n",
    "            wave, label = self.generate_audio()\n",
    "            msg = self.normalize_msg(self.msg(wave))\n",
    "            msg = np.expand_dims(msg, 2)\n",
    "            X[i] = msg\n",
    "            Y[i] = self.label_to_onehot(label)\n",
    "        np.save('%s/X_%07d-%07d' % (tmp_dir, start_i, n + start_i), X)\n",
    "        np.save('%s/Y_%07d-%07d' % (tmp_dir, start_i, n + start_i), Y)\n",
    "\n",
    "    def generate_train_set(self,\n",
    "                           n_total=100,\n",
    "                           n_per_job=10,\n",
    "                           n_pools=16,\n",
    "                           X_file='out/train_X.mem',\n",
    "                           Y_file='out/train_Y.mem',\n",
    "                           tmp_dir='out/train'):\n",
    "\n",
    "        assert n_total % n_per_job == 0\n",
    "\n",
    "        # init memory mapped files\n",
    "\n",
    "        if os.path.isfile(X_file): os.unlink(X_file)\n",
    "        train_X = np.memmap(\n",
    "            X_file,\n",
    "            np.float32,\n",
    "            'w+',\n",
    "            shape=(n_total, self.n_mels, self.msg_w, 1))\n",
    "\n",
    "        if os.path.isfile(Y_file): os.unlink(Y_file)\n",
    "        train_Y = np.memmap(\n",
    "            Y_file, np.float32, 'w+', shape=(n_total, len(self.labels)))\n",
    "\n",
    "        # cleanup tmp dir\n",
    "        if os.path.isdir(tmp_dir):\n",
    "            shutil.rmtree(tmp_dir)\n",
    "        os.makedirs(tmp_dir)\n",
    "\n",
    "        # launch generation in pool of workers\n",
    "\n",
    "        n_jobs = n_total // n_per_job\n",
    "        params = map(lambda x: [n_per_job, x * n_per_job, tmp_dir],\n",
    "                     range(n_jobs))\n",
    "\n",
    "        with Pool(n_pools) as p:\n",
    "            p.starmap(self._gen_training_samples, list(params))\n",
    "\n",
    "        # glue generated files together\n",
    "\n",
    "        for i in range(0, n_total, n_per_job):\n",
    "            X_file = '%s/X_%07d-%07d.npy' % (tmp_dir, i, i + n_per_job)\n",
    "            Y_file = '%s/Y_%07d-%07d.npy' % (tmp_dir, i, i + n_per_job)\n",
    "            X = np.load(X_file)\n",
    "            Y = np.load(Y_file)\n",
    "            train_X[i:i + n_per_job] = X\n",
    "            train_Y[i:i + n_per_job] = Y\n",
    "\n",
    "        train_X.flush()\n",
    "        train_Y.flush()\n",
    "\n",
    "        # cleanup\n",
    "        shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dg = DataGenerator('/d2/caches/tf-speech/train/audio')\n",
    "\n",
    "# dg.generate_train_set(\n",
    "#     n_total=100,\n",
    "#     n_per_job=10,\n",
    "#     n_pools=16,\n",
    "#     X_file='out/__train_X.npy',\n",
    "#     Y_file='out/__train_Y.npy',\n",
    "#     tmp_dir='out/__train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dg = DataGenerator('/d2/caches/tf-speech/train/audio')\n",
    "# print(dg._normalize_wave_len([1,2,3,4], min_samples=8))\n",
    "# print(dg._normalize_wave_len([1,2,3,4], max_samples=8, min_samples=8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
