{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random as _random\n",
    "import numpy\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_HOLDOUT_FILES: 3666\n"
     ]
    }
   ],
   "source": [
    "RND = 123\n",
    "N_FOLDS = 10\n",
    "N_HOLDOUT_SAMPLES = 4000\n",
    "N_HOLDOUT_FILES = int(N_HOLDOUT_SAMPLES / 12. * 11)\n",
    "print('N_HOLDOUT_FILES:', N_HOLDOUT_FILES)\n",
    "N_TRAIN = 1000000\n",
    "OUT_DIR = 'out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_random.seed(RND)\n",
    "numpy.random.seed(RND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../data-generator.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove/create dirs\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "shutil.rmtree('%s/holdout' % OUT_DIR, ignore_errors=True)\n",
    "os.makedirs('%s/holdout' % OUT_DIR, exist_ok=True)\n",
    "shutil.rmtree('%s/val' % OUT_DIR, ignore_errors=True)\n",
    "os.makedirs('%s/val' % OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGenerator('/d2/caches/tf-speech/train/audio')\n",
    "\n",
    "# adjust mixing options\n",
    "for k, v in dg.mix_with.items():\n",
    "    if '_background_noise_' in k:\n",
    "        v['probability'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'right': 2367, 'go': 2372, 'left': 2353, 'unknown': 41039, 'no': 2375, 'up': 2375, 'down': 2359, 'yes': 2377, 'off': 2357, 'on': 2367, 'stop': 2380}\n",
      "total samples for known words: 23682\n",
      "avg per known label: 2368.2\n"
     ]
    }
   ],
   "source": [
    "# get some stats on input data\n",
    "counts = {k: len(v) for k, v in dg.input_files.items()}\n",
    "print(counts)\n",
    "del counts['unknown']\n",
    "print('total samples for known words:', sum(counts.values()))\n",
    "print('avg per known label:', sum(counts.values()) / len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of all input files\n",
    "input_files = []\n",
    "for label, files in dg.input_files.items():\n",
    "    input_files.extend(files)\n",
    "\n",
    "np.random.shuffle(input_files)\n",
    "\n",
    "# balance number of 'unknown' labels\n",
    "MAX_UNKNOWN = 2357\n",
    "unknown = 0\n",
    "for i, f in enumerate(input_files):\n",
    "    if dg.get_label(f) == 'unknown':\n",
    "        unknown += 1\n",
    "        if unknown > MAX_UNKNOWN:\n",
    "            input_files[i] = None\n",
    "\n",
    "input_files = list(filter(lambda x: x is not None, input_files))\n",
    "dg.input_files = input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numer of unknown label files: 2357\n"
     ]
    }
   ],
   "source": [
    "print('numer of unknown label files:', len(dg.input_files['unknown']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate houldout set\n",
    "np.random.shuffle(input_files)\n",
    "holdout_files = input_files[:N_HOLDOUT_FILES]\n",
    "\n",
    "dg.val_files = {file: dg.get_label(file) for file in holdout_files}\n",
    "\n",
    "holdout_X, holdout_Y, holdout_files = dg.generate_val_set(\n",
    "    n=N_HOLDOUT_SAMPLES, return_files_list=True)\n",
    "\n",
    "np.save('%s/holdout/holdout_files.npy' % OUT_DIR, holdout_files)\n",
    "np.save('%s/holdout/holdout_X.npy' % OUT_DIR, holdout_X)\n",
    "np.save('%s/holdout/holdout_Y.npy' % OUT_DIR, holdout_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove holdout files from input\n",
    "input_files = list(set(input_files) ^ set(holdout_files))\n",
    "input_files = list(filter(lambda x: x != '(silence)', input_files))\n",
    "dg.input_files = input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1/10 of size 2238...\n",
      "n_val_samples: 2441\n",
      "fold 2/10 of size 2238...\n",
      "n_val_samples: 2441\n",
      "fold 6/10 of size 2237...\n",
      "n_val_samples: 2440\n",
      "fold 7/10 of size 2237...\n",
      "n_val_samples: 2440\n",
      "fold 8/10 of size 2237...\n",
      "n_val_samples: 2440\n",
      "fold 9/10 of size 2237...\n",
      "n_val_samples: 2440\n",
      "fold 10/10 of size 2237...\n",
      "n_val_samples: 2440\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "k = KFold(n_splits=N_FOLDS)\n",
    "s = k.split(input_files)\n",
    "\n",
    "i = 0\n",
    "\n",
    "for train, test in s:\n",
    "    print('fold %d/%d of size %d...' % (1 + i, N_FOLDS, len(test)))\n",
    "\n",
    "    dg.val_files = {\n",
    "        file: dg.get_label(file)\n",
    "        for file in np.array(input_files)[test]\n",
    "    }\n",
    "    \n",
    "    n_val_samples = int(len(test)/11.*12)\n",
    "    print('n_val_samples:', n_val_samples)\n",
    "\n",
    "    val_X, val_Y, val_files = dg.generate_val_set(\n",
    "        n=n_val_samples, return_files_list=True)\n",
    "    np.save('%s/val/val_files_%d.npy' % (OUT_DIR, i), val_files)\n",
    "    np.save('%s/val/val_X_%d.npy' % (OUT_DIR, i), val_X)\n",
    "    np.save('%s/val/val_Y_%d.npy' % (OUT_DIR, i), val_Y)\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gen_train_set():\n",
    "    dg.input_files = None\n",
    "    dg.val_files = {file: dg.get_label(file) for file in holdout_files}\n",
    "\n",
    "    dg.generate_train_set(\n",
    "        n_total=N_TRAIN,\n",
    "        n_per_job=1000,\n",
    "        n_pools=16,\n",
    "        X_file='%s/train_X.mem' % OUT_DIR,\n",
    "        Y_file='%s/train_Y.mem' % OUT_DIR,\n",
    "        files_file='%s/files.npy' % OUT_DIR,\n",
    "        tmp_dir='%s/train_tmp' % OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 s, sys: 26.8 s, total: 41.3 s\n",
      "Wall time: 7h 31s\n"
     ]
    }
   ],
   "source": [
    "%time _gen_train_set()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
