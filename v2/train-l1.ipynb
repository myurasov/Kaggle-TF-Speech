{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = '0'\n",
    "RND = 1\n",
    "RUN = 'A'\n",
    "OUT_DIR = 'out'\n",
    "TENSORBOARD_DIR = '/tensorboard/tf-speech-v2/%s' % RUN\n",
    "MODELS_DIR = '%s/models/run_%s/fold_$fold$' % (OUT_DIR, RUN)\n",
    "INPUT_SIZE = (64, 64, 1)  # n_mels x width x 1ch\n",
    "FOLDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../data-generator.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_batch(n, train_X, train_Y, train_files, val_files):\n",
    "    assert isinstance(val_files, set)\n",
    "\n",
    "    # extra random indexes to search for files not in val_files\n",
    "    def _extra_indexes():\n",
    "        return np.random.randint(0, len(train_X), size=int(n * 0.15))\n",
    "\n",
    "    ii = np.random.randint(0, len(train_X), size=n)\n",
    "    extra_ii = []\n",
    "\n",
    "    replaced = 0\n",
    "\n",
    "    # replace indexes with files occuring in val_files\n",
    "    for j in range(len(ii)):\n",
    "        if '(silence)' != train_files[ii[j]]:\n",
    "            while train_files[ii[j]] in val_files:\n",
    "                if len(extra_ii) == 0: extra_ii = _extra_indexes()\n",
    "                ii[j], extra_ii = extra_ii[0], extra_ii[1:]\n",
    "                replaced += 1\n",
    "\n",
    "    X = train_X[ii]\n",
    "    Y = train_Y[ii]\n",
    "    files = train_files[ii]\n",
    "    \n",
    "    return X, Y, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_X): 1000000\n"
     ]
    }
   ],
   "source": [
    "train_X = np.memmap('%s/train_X.mem' % OUT_DIR, np.float32,\n",
    "                    'r').reshape((-1, ) + INPUT_SIZE)\n",
    "train_Y = np.memmap('%s/train_Y.mem' % OUT_DIR, np.float32, 'r').reshape(\n",
    "    (-1, len(LABELS)))\n",
    "\n",
    "train_files = np.load('%s/train_files.npy' % OUT_DIR)\n",
    "\n",
    "assert len(train_Y) == len(train_X)\n",
    "assert len(train_files) == len(train_X)\n",
    "\n",
    "print('len(train_X):', len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "len(val_X): 2441\n",
      "models_dir: out/models/run_A/fold_0\n",
      "fold: 1\n",
      "len(val_X): 2441\n",
      "models_dir: out/models/run_A/fold_1\n",
      "fold: 2\n",
      "len(val_X): 2441\n",
      "models_dir: out/models/run_A/fold_2\n",
      "fold: 3\n",
      "len(val_X): 2440\n",
      "models_dir: out/models/run_A/fold_3\n",
      "fold: 4\n",
      "len(val_X): 2440\n",
      "models_dir: out/models/run_A/fold_4\n",
      "fold: 5\n",
      "len(val_X): 2440\n",
      "models_dir: out/models/run_A/fold_5\n",
      "fold: 6\n",
      "len(val_X): 2440\n",
      "models_dir: out/models/run_A/fold_6\n",
      "fold: 7\n",
      "len(val_X): 2440\n",
      "models_dir: out/models/run_A/fold_7\n",
      "fold: 8\n",
      "len(val_X): 2440\n",
      "models_dir: out/models/run_A/fold_8\n",
      "fold: 9\n",
      "len(val_X): 2440\n",
      "models_dir: out/models/run_A/fold_9\n"
     ]
    }
   ],
   "source": [
    "for fold in range(FOLDS):\n",
    "\n",
    "    print('fold:', fold)\n",
    "\n",
    "    # read val data\n",
    "    val_X = np.load('%s/val/val_X_%d.npy' % (OUT_DIR, fold))\n",
    "    val_Y = np.load('%s/val/val_Y_%d.npy' % (OUT_DIR, fold))\n",
    "    val_files = np.load('%s/val/val_files_%d.npy' % (OUT_DIR, fold))\n",
    "    assert len(val_X) == len(val_files)\n",
    "    assert len(val_Y) == len(val_files)\n",
    "    print('len(val_X):', len(val_X))\n",
    "    val_files = set(val_files)\n",
    "\n",
    "    # create dir to store models\n",
    "    models_dir = MODELS_DIR.replace('$fold$', str(fold))\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    print('models_dir:', models_dir)\n",
    "\n",
    "    def train_generator(n_per_batch):\n",
    "        while True:\n",
    "            X, Y, files = choose_batch(n_per_batch, train_X, train_Y, train_files, val_files)\n",
    "            yield (X, Y)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
