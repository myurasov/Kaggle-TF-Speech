{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RND = 0\n",
    "RUN = 'B3'\n",
    "OUT_DIR = 'out'\n",
    "TRAIN_TMP_DIR = OUT_DIR + '/train'\n",
    "INPUT_DIR = '/d2/caches/tf-speech/train/audio'\n",
    "TENSORBOARD_DIR = '/tensorboard/tf-speech/%s' % RUN\n",
    "MODELS_DIR = '%s/models/%s' % (OUT_DIR, RUN)\n",
    "INPUT_SIZE = (64, 64, 1)  # n_mels x width x 1ch\n",
    "MSG_NORM_MEAN = 116.536\n",
    "MSG_NORM_STD = 21.5913\n",
    "LABELS = [\n",
    "    'yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go',\n",
    "    'unknown', 'silence'\n",
    "]\n",
    "\n",
    "N_VAL_SAMPLES = 2500\n",
    "N_TRAIN_SAMPLES = 500000  # how many training samples to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'lib.ipynb'\n",
    "%run 'data-generator.ipynb'\n",
    "%run 'models.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tensorboard data\n",
    "if os.path.isdir(TENSORBOARD_DIR): shutil.rmtree(TENSORBOARD_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init data gen\n",
    "dg = DataGenerator(input_dir=INPUT_DIR, labels=LABELS)\n",
    "dg.n_mels = INPUT_SIZE[0]\n",
    "dg.msg_w = INPUT_SIZE[1]\n",
    "# normalization params\n",
    "dg.samplewise_norm = True\n",
    "dg.msg_std = MSG_NORM_STD\n",
    "dg.msg_mean = MSG_NORM_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val samples: 2500\n"
     ]
    }
   ],
   "source": [
    "# generate/load val data\n",
    "\n",
    "val_files_path = OUT_DIR + '/val_files.npy'\n",
    "val_X_path = OUT_DIR + '/val_X.npy'\n",
    "val_Y_path = OUT_DIR + '/val_Y.npy'\n",
    "\n",
    "if not os.path.isfile(val_files_path):\n",
    "    # generate, save\n",
    "    dg.val_files = {}\n",
    "    val_X, val_Y = dg.generate_val_set(n=N_VAL_SAMPLES)\n",
    "    np.save(val_files_path, dg.val_files)\n",
    "    np.save(val_X_path, val_X)\n",
    "    np.save(val_Y_path, val_Y)\n",
    "else:\n",
    "    # load\n",
    "    dg.val_files = np.load(val_files_path)\n",
    "    val_X = np.load(val_X_path)\n",
    "    val_Y = np.load(val_Y_path)\n",
    "\n",
    "assert len(val_X) == len(val_Y)\n",
    "print('val samples: %d' % len(val_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples: 500000\n"
     ]
    }
   ],
   "source": [
    "# generate/load training data\n",
    "\n",
    "train_X_file = '%s/train_X.npy' % OUT_DIR\n",
    "train_Y_file = '%s/train_Y.npy' % OUT_DIR\n",
    "\n",
    "if not os.path.isfile(train_X_file):\n",
    "    dg.generate_train_set(\n",
    "        n_total=N_TRAIN_SAMPLES,\n",
    "        n_per_job=1000,\n",
    "        n_pools=16,\n",
    "        X_file=train_X_file,\n",
    "        Y_file=train_Y_file,\n",
    "        tmp_dir=TRAIN_TMP_DIR)\n",
    "\n",
    "train_X = np.load(train_X_file, mmap_mode='r')  # open in memmap mode\n",
    "train_Y = np.load(train_Y_file)\n",
    "\n",
    "assert len(train_X) == len(train_Y)\n",
    "print('training samples: %d' % len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Model_2(input_size=INPUT_SIZE, output_size=len(LABELS))\n",
    "model.build()\n",
    "optimizer = RMSprop(lr=0.0001)\n",
    "model.m.compile(\n",
    "    optimizer=optimizer, loss=categorical_crossentropy, metrics=['accuracy']\\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create models dir\n",
    "if os.path.isdir(MODELS_DIR): shutil.rmtree(MODELS_DIR)\n",
    "os.makedirs(MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # train model\n",
    "\n",
    "# N_BATCH = 500\n",
    "# N_EPOCHS = 100\n",
    "\n",
    "# model.m.fit(\n",
    "#     x=train_X,\n",
    "#     y=train_Y,\n",
    "#     batch_size=N_BATCH,\n",
    "#     epochs=N_EPOCHS,\n",
    "#     verbose=1,\n",
    "#     callbacks=[\n",
    "#         TensorBoard(log_dir=TENSORBOARD_DIR, histogram_freq=0),\n",
    "#         ModelCheckpoint(\n",
    "#             MODELS_DIR +\n",
    "#             '/e{epoch:03d}-l={loss:.5f}-vl={val_loss:.5f}-a={acc:.5f}-va={val_acc:.5f}.h5',\n",
    "#             monitor='val_acc',\n",
    "#             verbose=0,\n",
    "#             save_best_only=False,\n",
    "#             save_weights_only=False,\n",
    "#             mode='auto'),\n",
    "#         EarlyStopping(\n",
    "#             monitor='val_acc',\n",
    "#             min_delta=0.001,\n",
    "#             patience=2,\n",
    "#             verbose=1,\n",
    "#             mode='auto')\n",
    "#     ],\n",
    "#     validation_data=(val_X, val_Y),\n",
    "#     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples per epoch: 100000\n",
      "\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 15s - loss: 2.1209 - acc: 0.2701 - val_loss: 1.2508 - val_acc: 0.5900\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 15s - loss: 1.4812 - acc: 0.5036 - val_loss: 0.8843 - val_acc: 0.7092\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 15s - loss: 1.1964 - acc: 0.6029 - val_loss: 0.5865 - val_acc: 0.8088\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 15s - loss: 1.0231 - acc: 0.6652 - val_loss: 0.4890 - val_acc: 0.8444\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 15s - loss: 0.9126 - acc: 0.7061 - val_loss: 0.4462 - val_acc: 0.8552\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 15s - loss: 0.8196 - acc: 0.7370 - val_loss: 0.4314 - val_acc: 0.8608\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 15s - loss: 0.7304 - acc: 0.7643 - val_loss: 0.3850 - val_acc: 0.8824\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 15s - loss: 0.6467 - acc: 0.7916 - val_loss: 0.3567 - val_acc: 0.8824\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 15s - loss: 0.5694 - acc: 0.8163 - val_loss: 0.3519 - val_acc: 0.8976\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 15s - loss: 0.5310 - acc: 0.8298 - val_loss: 0.3694 - val_acc: 0.8940\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 15s - loss: 0.4999 - acc: 0.8394 - val_loss: 0.3388 - val_acc: 0.9012\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 15s - loss: 0.4383 - acc: 0.8579 - val_loss: 0.3840 - val_acc: 0.8896\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 15s - loss: 0.3769 - acc: 0.8773 - val_loss: 0.3134 - val_acc: 0.9140\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 15s - loss: 0.3245 - acc: 0.8945 - val_loss: 0.3171 - val_acc: 0.9048\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 14s - loss: 0.3031 - acc: 0.8999 - val_loss: 0.3655 - val_acc: 0.9144\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 14s - loss: 0.2825 - acc: 0.9085 - val_loss: 0.3799 - val_acc: 0.9048\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 14s - loss: 0.2407 - acc: 0.9210 - val_loss: 0.3781 - val_acc: 0.9124\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 15s - loss: 0.2076 - acc: 0.9321 - val_loss: 0.3704 - val_acc: 0.9132\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 14s - loss: 0.1797 - acc: 0.9414 - val_loss: 0.3473 - val_acc: 0.9116\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 14s - loss: 0.1664 - acc: 0.9451 - val_loss: 0.3835 - val_acc: 0.9224\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 15s - loss: 0.1563 - acc: 0.9484 - val_loss: 0.4228 - val_acc: 0.9024\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 14s - loss: 0.1407 - acc: 0.9535 - val_loss: 0.4175 - val_acc: 0.9120\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 15s - loss: 0.1246 - acc: 0.9596 - val_loss: 0.3955 - val_acc: 0.9148\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 15s - loss: 0.1131 - acc: 0.9630 - val_loss: 0.3898 - val_acc: 0.9112\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 15s - loss: 0.1022 - acc: 0.9665 - val_loss: 0.4167 - val_acc: 0.9180\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 15s - loss: 0.1020 - acc: 0.9666 - val_loss: 0.4687 - val_acc: 0.9084\n",
      "Epoch 00025: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f98abc32518>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "N_PER_BATCH = 500\n",
    "STEPS_PER_EPOCH = len(\n",
    "    train_X) // N_PER_BATCH // 5  # last number splits train set into # epochs\n",
    "N_EPOCHS = 100\n",
    "\n",
    "print('# samples per epoch: %d\\n' % (STEPS_PER_EPOCH * N_PER_BATCH))\n",
    "\n",
    "\n",
    "def train_generator(n_per_batch):\n",
    "    start_i = 0\n",
    "    while True:\n",
    "        if start_i >= len(train_X): start_i = 0\n",
    "        batch_X = train_X[start_i:start_i + n_per_batch]\n",
    "        batch_Y = train_Y[start_i:start_i + n_per_batch]\n",
    "        yield (batch_X, batch_Y)\n",
    "        start_i += n_per_batch\n",
    "\n",
    "\n",
    "model.m.fit_generator(\n",
    "    train_generator(N_PER_BATCH),\n",
    "    STEPS_PER_EPOCH,\n",
    "    epochs=N_EPOCHS,\n",
    "    validation_data=(val_X, val_Y),\n",
    "    callbacks=[\n",
    "        TensorBoard(log_dir=TENSORBOARD_DIR),\n",
    "        ModelCheckpoint(\n",
    "            MODELS_DIR +\n",
    "            '/e{epoch:03d}-l={loss:.5f}-vl={val_loss:.5f}-a={acc:.5f}-va={val_acc:.5f}.h5',\n",
    "            monitor='val_acc',\n",
    "            verbose=0,\n",
    "            save_best_only=False,\n",
    "            save_weights_only=False,\n",
    "            mode='auto'),\n",
    "        EarlyStopping(\n",
    "            monitor='val_acc',\n",
    "            min_delta=0.0001,\n",
    "            patience=5,\n",
    "            verbose=1,\n",
    "            mode='auto')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
