{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RND = 0\n",
    "RUN = 'B'\n",
    "OUT_DIR = 'out'\n",
    "TRAIN_TMP_DIR = OUT_DIR + '/train'\n",
    "INPUT_DIR = '/d2/caches/tf-speech/train/audio'\n",
    "TENSORBOARD_DIR = '/tensorboard/tf-speech/%s' % RUN\n",
    "MODELS_DIR = '%s/models/%s' % (OUT_DIR, RUN)\n",
    "INPUT_SIZE = (64, 64, 1)  # n_mels x width x 1ch\n",
    "MSG_NORM_MEAN = 116.536\n",
    "MSG_NORM_STD = 21.5913\n",
    "LABELS = [\n",
    "    'yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go',\n",
    "    'unknown', 'silence'\n",
    "]\n",
    "\n",
    "N_VAL_SAMPLES = 2500\n",
    "N_TRAIN_SAMPLES = 500000  # how many training samples to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'lib.ipynb'\n",
    "%run 'data-generator.ipynb'\n",
    "%run 'models.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tensorboard data\n",
    "if os.path.isdir(TENSORBOARD_DIR): shutil.rmtree(TENSORBOARD_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init data gen\n",
    "dg = DataGenerator(input_dir=INPUT_DIR, labels=LABELS)\n",
    "dg.n_mels = INPUT_SIZE[0]\n",
    "dg.msg_w = INPUT_SIZE[1]\n",
    "# normalization params\n",
    "dg.samplewise_norm = True\n",
    "dg.msg_std = MSG_NORM_STD\n",
    "dg.msg_mean = MSG_NORM_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val samples: 2500\n"
     ]
    }
   ],
   "source": [
    "# generate/load val data\n",
    "\n",
    "val_files_path = OUT_DIR + '/val_files.npy'\n",
    "val_X_path = OUT_DIR + '/val_X.npy'\n",
    "val_Y_path = OUT_DIR + '/val_Y.npy'\n",
    "\n",
    "if not os.path.isfile(val_files_path):\n",
    "    # generate, save\n",
    "    dg.val_files = {}\n",
    "    val_X, val_Y = dg.generate_val_set(n=N_VAL_SAMPLES)\n",
    "    np.save(val_files_path, dg.val_files)\n",
    "    np.save(val_X_path, val_X)\n",
    "    np.save(val_Y_path, val_Y)\n",
    "else:\n",
    "    # load\n",
    "    dg.val_files = np.load(val_files_path)\n",
    "    val_X = np.load(val_X_path)\n",
    "    val_Y = np.load(val_Y_path)\n",
    "\n",
    "assert len(val_X) == len(val_Y)\n",
    "print('val samples: %d' % len(val_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples: 500000\n"
     ]
    }
   ],
   "source": [
    "# generate/load training data\n",
    "\n",
    "train_X_file = '%s/train_X.npy' % OUT_DIR\n",
    "train_Y_file = '%s/train_Y.npy' % OUT_DIR\n",
    "\n",
    "if not os.path.isfile(train_X_file):\n",
    "    dg.generate_train_set(\n",
    "        n_total=N_TRAIN_SAMPLES,\n",
    "        n_per_job=1000,\n",
    "        n_pools=16,\n",
    "        X_file=train_X_file,\n",
    "        Y_file=train_Y_file,\n",
    "        tmp_dir=TRAIN_TMP_DIR)\n",
    "\n",
    "train_X = np.load(train_X_file, mmap_mode='r')  # open in memmap mode\n",
    "train_Y = np.load(train_Y_file)\n",
    "\n",
    "assert len(train_X) == len(train_Y)\n",
    "print('training samples: %d' % len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Model_2(input_size=INPUT_SIZE, output_size=len(LABELS))\n",
    "model.build()\n",
    "optimizer = RMSprop(lr=0.001, decay=0.0)\n",
    "model.m.compile(\n",
    "    optimizer=optimizer, loss=categorical_crossentropy, metrics=['accuracy']\\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create models dir\n",
    "if os.path.isdir(MODELS_DIR): shutil.rmtree(MODELS_DIR)\n",
    "os.makedirs(MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # train model\n",
    "\n",
    "# N_BATCH = 500\n",
    "# N_EPOCHS = 100\n",
    "\n",
    "# model.m.fit(\n",
    "#     x=train_X,\n",
    "#     y=train_Y,\n",
    "#     batch_size=N_BATCH,\n",
    "#     epochs=N_EPOCHS,\n",
    "#     verbose=1,\n",
    "#     callbacks=[\n",
    "#         TensorBoard(log_dir=TENSORBOARD_DIR, histogram_freq=0),\n",
    "#         ModelCheckpoint(\n",
    "#             MODELS_DIR +\n",
    "#             '/e{epoch:03d}-l={loss:.5f}-vl={val_loss:.5f}-a={acc:.5f}-va={val_acc:.5f}.h5',\n",
    "#             monitor='val_acc',\n",
    "#             verbose=0,\n",
    "#             save_best_only=False,\n",
    "#             save_weights_only=False,\n",
    "#             mode='auto'),\n",
    "#         EarlyStopping(\n",
    "#             monitor='val_acc',\n",
    "#             min_delta=0.001,\n",
    "#             patience=2,\n",
    "#             verbose=1,\n",
    "#             mode='auto')\n",
    "#     ],\n",
    "#     validation_data=(val_X, val_Y),\n",
    "#     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples per epoch: 100000\n",
      "\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 15s - loss: 1.7834 - acc: 0.3954 - val_loss: 0.5652 - val_acc: 0.8088\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 14s - loss: 0.7613 - acc: 0.7534 - val_loss: 0.4567 - val_acc: 0.8860\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 14s - loss: 0.4291 - acc: 0.8663 - val_loss: 0.3874 - val_acc: 0.9064\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 14s - loss: 0.2952 - acc: 0.9110 - val_loss: 0.3451 - val_acc: 0.9104\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 14s - loss: 0.2448 - acc: 0.9240 - val_loss: 0.4435 - val_acc: 0.9192\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 14s - loss: 0.2878 - acc: 0.9123 - val_loss: 0.4496 - val_acc: 0.9240\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 14s - loss: 0.1921 - acc: 0.9413 - val_loss: 0.4511 - val_acc: 0.9240\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 14s - loss: 0.1569 - acc: 0.9536 - val_loss: 0.4690 - val_acc: 0.9168\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 14s - loss: 0.1341 - acc: 0.9604 - val_loss: 0.3725 - val_acc: 0.9236\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 14s - loss: 0.0994 - acc: 0.9700 - val_loss: 0.4970 - val_acc: 0.9260\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 14s - loss: 0.1300 - acc: 0.9612 - val_loss: 0.5216 - val_acc: 0.9216\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 14s - loss: 0.1125 - acc: 0.9669 - val_loss: 0.4919 - val_acc: 0.9120\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 15s - loss: 0.1079 - acc: 0.9695 - val_loss: 0.4893 - val_acc: 0.9196\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 14s - loss: 0.0981 - acc: 0.9731 - val_loss: 0.3992 - val_acc: 0.9208\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1977a31550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "N_PER_BATCH = 500\n",
    "STEPS_PER_EPOCH = len(\n",
    "    train_X) // N_PER_BATCH // 5  # last number splits train set into # epochs\n",
    "N_EPOCHS = 100\n",
    "\n",
    "print('# samples per epoch: %d\\n' % (STEPS_PER_EPOCH * N_PER_BATCH))\n",
    "\n",
    "\n",
    "def train_generator(n_per_batch):\n",
    "    start_i = 0\n",
    "    while True:\n",
    "        if start_i >= len(train_X): start_i = 0\n",
    "        batch_X = train_X[start_i:start_i + n_per_batch]\n",
    "        batch_Y = train_Y[start_i:start_i + n_per_batch]\n",
    "        yield (batch_X, batch_Y)\n",
    "        start_i += n_per_batch\n",
    "\n",
    "\n",
    "model.m.fit_generator(\n",
    "    train_generator(N_PER_BATCH),\n",
    "    STEPS_PER_EPOCH,\n",
    "    epochs=N_EPOCHS,\n",
    "    validation_data=(val_X, val_Y),\n",
    "    callbacks=[\n",
    "        TensorBoard(log_dir=TENSORBOARD_DIR),\n",
    "        ModelCheckpoint(\n",
    "            MODELS_DIR +\n",
    "            '/e{epoch:03d}-l={loss:.5f}-vl={val_loss:.5f}-a={acc:.5f}-va={val_acc:.5f}.h5',\n",
    "            monitor='val_acc',\n",
    "            verbose=0,\n",
    "            save_best_only=False,\n",
    "            save_weights_only=False,\n",
    "            mode='auto'),\n",
    "        EarlyStopping(\n",
    "            monitor='val_acc',\n",
    "            min_delta=0.001,\n",
    "            patience=3,\n",
    "            verbose=1,\n",
    "            mode='auto')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
